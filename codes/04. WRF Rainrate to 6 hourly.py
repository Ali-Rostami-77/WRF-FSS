# This code generates 6 hourly rainrate files from rainrate files
# The My project performs validation of precipiation for every 6 hours

import xarray as xr
import pandas as pd
import glob
import os
from tqdm import tqdm

def process_6hour_chunks(hourly_dir, output_dir):
    """
    Process files in strict 6-file chunks, summing precipitation and naming output after last file
    """
    # Get all .nc files sorted by time (the NetCDF files that already generated by previous code)
    hourly_files = sorted(glob.glob(os.path.join(hourly_dir, '*.nc')))
    
    if not hourly_files:
        raise ValueError(f"No .nc files found in {hourly_dir}")
    
    print(f"Found {len(hourly_files)} hourly files")
    
    # Calculate number of complete 6-file chunks 
    num_chunks = len(hourly_files) // 6 # here by changing the number, can make 24 hourly files too 
    # if changing 6 to other numbers do not forget to change the other 6s.
    if num_chunks == 0:
        raise ValueError("Not enough files for even one 6-hour chunk")
    
    print(f"Will process {num_chunks} complete 6-hour chunks")
    
    # Process each 6-file chunk
    os.makedirs(output_dir, exist_ok=True)
    
    for chunk_num in tqdm(range(num_chunks), desc="Processing chunks"):
        chunk_files = hourly_files[chunk_num*6 : (chunk_num+1)*6]
        
        # Get end timestamp from last file's name
        last_file = os.path.basename(chunk_files[-1])
        try:
            parts = last_file.split('_')
            end_dt_str = f"{parts[2]}_{parts[3][:2]}00"  # YYYYMMDD_HH00
        except:
            raise ValueError(f"Couldn't parse timestamp from {last_file}")
        
        # Initialize sums
        rainnc_sum = None
        rainc_sum = None
        template = None
        
        # Process each file in chunk
        for file in chunk_files:
            try:
                with xr.open_dataset(file) as ds:
                    # Handle variable names
                    rainnc = ds.get('RAINNC_rate', ds.get('RAINNC'))
                    rainc = ds.get('RAINC_rate', ds.get('RAINC'))
                    # in some other files the variable name changed to ..._rate, now it handles them too.
                    
                    if rainnc_sum is None:
                        template = ds.copy()
                        rainnc_sum = rainnc.copy()
                        rainc_sum = rainc.copy()
                    else:
                        rainnc_sum += rainnc
                        rainc_sum += rainc
            except Exception as e:
                raise ValueError(f"Error processing {file}: {e}")
        
        # Create output dataset
        # Here make new varables and stores the new values into them.
        ds_out = template.copy()
        ds_out['RAINNC_6hr'] = rainnc_sum
        ds_out['RAINC_6hr'] = rainc_sum
        
        # Update time to last file's time
        if 'XTIME' in ds_out:
            ds_out['XTIME'].values = pd.to_datetime(end_dt_str, format='%Y%m%d_%H%M').to_numpy()
        
        # Save output 
        out_file = os.path.join(output_dir, f"wrf_rain_accum_6hr_{end_dt_str}.nc")
        ds_out.to_netcdf(out_file)
        print(f"Created: {out_file}")

# Adding Paths
hourly_dir = "Input Path/hourly_split-D?/"
output_dir = "Input path/6hr_accum-D3/"

process_6hour_chunks(hourly_dir, output_dir)